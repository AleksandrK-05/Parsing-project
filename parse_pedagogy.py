import requests
from bs4 import BeautifulSoup
import json
from urllib.parse import urljoin

def parse_pedsovet_articles():
    """
    –ü–∞—Ä—Å–∏–Ω–≥ –∫–∞—Ä—Ç–æ—á–µ–∫ —Å—Ç–∞—Ç–µ–π —Å —Å–∞–π—Ç–∞ pedsovet.org
    """
    url = "https://pedsovet.org/"
    
    try:
        
        print(" –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É...")
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        
        # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç —Å —Ç–∞–∫–∏–º –∂–µ –Ω–∞–∑–≤–∞–Ω–∏–µ–º, —á—Ç–æ–±—ã –±—ã–ª–æ —É–¥–æ–±–Ω–µ–Ω
        soup = BeautifulSoup(response.text, 'html.parser')
        articles_data = []
        

        print(" –ò—â–µ–º –∫–∞—Ä—Ç–æ—á–∫–∏ —Å—Ç–∞—Ç–µ–π...")
        cards = soup.find_all('div', class_=lambda x: x and any(word in str(x) for word in ['card', 'item', 'news', 'article', 'post']))
        
        # –¥—Ä—É–≥–æ–π –ø–æ–∏—Å–∫, –µ—Å–ª–∏ —Ç–∞–º –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å
        if not cards:
            cards = soup.select('div[class*="card"], div[class*="item"], div[class*="news"]')
        
        print(f" –ù–∞–π–¥–µ–Ω–æ –∫–∞—Ä—Ç–æ—á–µ–∫: {len(cards)}")
        
        for i, card in enumerate(cards, 1):
            try:
                # —Ç—É—Ç –∏—â—É—Ç—Å—è –∑–∞–≥–æ–ª–æ–≤–∫–∏
                title_elem = card.find(['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'a', 'span', 'div'])
                if not title_elem:
                    continue
                    
                title = title_elem.get_text(strip=True)
                if not title or len(title) < 5:
                    continue
                
                # —Ç—É—Ç –∏—â–µ—Ç—Å—è —Å—Å—ã–ª–∫–∞
                link_elem = card.find('a', href=True)
                if link_elem:
                    link = link_elem['href']
                    if link.startswith('/'):
                        link = urljoin(url, link)
                else:
                    link = "–°—Å—ã–ª–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
                
                # —Ç—É—Ç –ø—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ 
                articles_data.append({
                    'id': i,
                    'title': title,
                    'link': link
                })
                
                print(f" –û–±—Ä–∞–±–æ—Ç–∞–Ω–∞ –∫–∞—Ä—Ç–æ—á–∫–∞ {i}: {title[:50]}...")
                
            except Exception as e:
                print(f" –û—à–∏–±–∫–∞ –≤ –∫–∞—Ä—Ç–æ—á–∫–µ {i}: {e}")
                continue
        
        # —Ç—É—Ç –≤—ã–≤–æ–¥–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        print("\n" + "="*60)
        print(" –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–ê–†–°–ò–ù–ì–ê:")
        print("="*60)
        
        for article in articles_data:
            print(f" {article['title']}")
            print(f"üîó {article['link']}")
            print()
        
        # —Ç—É—Ç —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª –≤ json 
        with open('pedsovet_articles.json', 'w', encoding='utf-8') as f:
            json.dump(articles_data, f, ensure_ascii=False, indent=2)
        
        print(f" –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: pedsovet_articles.json")
        print(f" –í—Å–µ–≥–æ —Å—Ç–∞—Ç–µ–π: {len(articles_data)}")
        
        return articles_data
        
    except requests.RequestException as e:
        print(f" –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
        return []
    except Exception as e:
        print(f" –û–±—â–∞—è –æ—à–∏–±–∫–∞: {e}")
        return []

if __name__ == "__main__":

    parse_pedsovet_articles()

